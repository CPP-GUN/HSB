\section{Conclusions and Implications}

This study develops a unified, data-driven modeling framework to evaluate, compare, forecast, and optimize national artificial intelligence (AI) development capability. By maintaining a consistent indicator system and a fixed evaluation rule throughout all tasks, the proposed framework forms a closed analytical loop that ensures cross-country and cross-period comparability, as well as full traceability of results.

From a methodological perspective, the factor identification and structural analysis reveal that AI development is not driven by isolated indicators, but by a tightly coupled system involving infrastructure capacity, human capital, policy environment, and innovation output. The composite evaluation results for 2025 demonstrate clear stratification among countries, reflecting persistent structural advantages rather than short-term fluctuations. Extending the analysis to the 2026--2035 horizon, the forecasting task shows that, under stable structural conditions, global AI competitiveness rankings exhibit strong inertia, with only limited position changes among mid-tier countries. This finding suggests that AI leadership is path-dependent and difficult to overturn without sustained, long-term investment.

Robustness and error diagnostics further support the reliability of the conclusions. High rank-order consistency ($\rho_s = 0.9758$) and a moderate median prediction error (median MAPE $\approx 0.1035$) indicate that the results are not sensitive to specific parameter settings or single-model assumptions. Consequently, the observed ranking patterns and trends can be regarded as structurally driven rather than model-induced artifacts.

On this basis, the investment optimization task translates analytical results into actionable policy insights. Under the assumption of an additional one-trillion-yuan budget for China starting in 2026, the optimal allocation strategy emphasizes an infrastructure-first approach, complemented by coordinated investment in talent cultivation and policy support. This allocation pattern reflects the high marginal contribution of foundational capacity to long-term AI competitiveness, while highlighting the necessity of institutional and human capital alignment.

Several limitations should be acknowledged. First, the analysis relies on publicly available and lagged data, which may not fully capture emerging technological breakthroughs. Second, the forecasting results are conditional on a stable structural assumption and do not account for disruptive policy shifts or technological shocks. Despite these limitations, the proposed framework provides a transparent, extensible, and reproducible decision-support tool for evaluating national AI competitiveness and guiding strategic investment planning.

Overall, this study offers both a quantitative assessment of the current global AI landscape and a forward-looking perspective on its evolution, with implications for policymakers seeking to design evidence-based and strategically coherent AI development strategies.
