\section{Basic Assumption}

To ensure the feasibility, consistency, and interpretability of the proposed models, the following basic assumptions are made.

$\blacktriangleright$ \textbf{Hypothesis 1: Assume that national AI development capability is a latent attribute that can be approximated by a finite set of observable and quantifiable indicators.}

\textbf{Legitimacy: }At the national level, AI development is manifested through measurable outcomes and resource inputs recorded in public statistics. Although the true capability cannot be observed directly, its major characteristics can be reasonably inferred from aggregated, quantifiable indicators.

$\blacktriangleright$ \textbf{Hypothesis 2: Assume that all indicators within the same evaluation year are cross-sectionally consistent.}

\textbf{Legitimacy: }Although data may be collected from slightly different release years, AI development is a long-term process. Minor temporal discrepancies do not significantly affect national-level competitiveness comparisons and help simplify the modeling process.

$\blacktriangleright$ \textbf{Hypothesis 3: Assume that the indicators are independent of each other in the weighting and evaluation stages.}

\textbf{Justification :}While interactions among indicators exist, explicitly modeling such dependencies would increase complexity and reduce interpretability. Treating indicators as independent avoids double counting and ensures the applicability of entropy-based and multi-criteria evaluation methods.

$\blacktriangleright$ \textbf{Hypothesis 4: Assume that the fundamental mechanisms of AI development remain stable during the forecasting and optimization period.}

\textbf{Justification :}National AI strategies, infrastructure construction, and talent cultivation generally evolve gradually. This stability makes trend-based prediction and investment optimization reasonable and analytically tractable.
