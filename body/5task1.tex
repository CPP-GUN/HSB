% =========================
% body/5task1.tex
% =========================
\FloatBarrier
\section{Task 1: Analysis of AI Development Factors}

Task~1 aims to \emph{reveal the internal structure} of national AI capability from the 24-indicator system.
Rather than prespecifying causal links, we use cross-country co-movement to identify (i) tightly coupled factor groups,
(ii) dominant low-dimensional directions, and (iii) a small set of high-leverage indicators.
These structural outputs support Task~2 (objective evaluation) and inform Task~4 (synergy-aware constraints).

\subsection{Quantification of Key Indicators}

Let the min--max normalized indicator matrix be
\begin{equation}
X=[x_{ij}] \in \mathbb{R}^{n\times p},\qquad n=10,\; p=24,
\end{equation}
where $x_{ij}$ is the normalized value of indicator $j$ for country $i$.
To remove scale effects across heterogeneous indicators, we apply
\begin{equation}
x_{ij}=\frac{x_{ij}^{\mathrm{raw}}-\min(x_j)}{\max(x_j)-\min(x_j)}\in[0,1].
\end{equation}
Matrix $X$ is the common input for correlation, clustering, and PCA in this task.

\subsection{Correlation Structure and Interaction Mechanism}

\paragraph{Correlation map and strong-link set.}
We quantify linear association by Pearson correlation:
\begin{equation}
r_{jk}=
\frac{\sum_{i=1}^{n}(x_{ij}-\bar{x}_j)(x_{ik}-\bar{x}_k)}
{\sqrt{\sum_{i=1}^{n}(x_{ij}-\bar{x}_j)^2}\sqrt{\sum_{i=1}^{n}(x_{ik}-\bar{x}_k)^2}},
\qquad
R=[r_{jk}] \in \mathbb{R}^{p\times p}.
\end{equation}
To focus on interpretable dependencies, we define the strong-correlation edge set
\begin{equation}
\mathcal{E}=\{(j,k)\mid |r_{jk}|>\tau,\; j<k\},
\end{equation}
where $\tau$ is a fixed threshold (used consistently in Task~4 to impose synergy constraints).
The heatmap in Fig.~\ref{fig:task1_corr_cluster}\subref{fig:task1_corr} shows a dense positive-correlation backbone,
suggesting that talent, R\&D investment, market scale, and compute infrastructure often advance jointly.

\paragraph{Hierarchical clustering (group-level structure)\cite{Ward1963}.}
To move beyond pairwise links, we cluster indicators using correlation distance
\begin{equation}
d_{jk}=1-|r_{jk}|,
\end{equation}
and average linkage between clusters $C_a$ and $C_b$:
\begin{equation}
D(C_a,C_b)=\frac{1}{|C_a||C_b|}\sum_{j\in C_a}\sum_{k\in C_b} d_{jk}.
\end{equation}
The dendrogram in Fig.~\ref{fig:task1_corr_cluster}\subref{fig:task1_cluster} recovers coherent modules,
typically separating (i) \emph{investment--market--infrastructure} factors from (ii) \emph{talent--knowledge production} factors.
This validates that the indicator system is multidimensional but internally coordinated.

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[t]{0.49\textwidth}
    \centering
    \includegraphics[width=\linewidth]{\detokenize{figure/task1/fig1_en_Correlation Heatmap of AI Development Factors.pdf}}
    \caption{Correlation heatmap of 24 indicators.}
    \label{fig:task1_corr}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.49\textwidth}
    \centering
    \includegraphics[width=\linewidth]{\detokenize{figure/task1/fig2_en_Hierarchical Clustering Dendrogram of AI Development Factors.pdf}}
    \caption{Hierarchical clustering dendrogram.}
    \label{fig:task1_cluster}
  \end{subfigure}
  \caption{Pairwise association and group structure of AI development factors.}
  \label{fig:task1_corr_cluster}
\end{figure}

\paragraph{Principal component structure (dominant dimensions)\cite{Hotelling1933}.}
High correlations imply redundancy, so we use PCA to extract dominant directions.
Let
\begin{equation}
\tilde{X}=X-\mathbf{1}\bar{X}^T,\qquad
C=\frac{1}{n-1}\tilde{X}^T\tilde{X},
\end{equation}
and eigen-decompose
\begin{equation}
C=V\Lambda V^T.
\end{equation}
We retain the smallest $m$ components that explain a high share of variance (in our results, the first four PCs explain $>90\%$;
see Fig.~\ref{fig:task1_pca_stack}\subref{fig:task1_pca}).
This indicates that cross-country AI capability differences can be summarized by a low-dimensional latent structure.

\paragraph{Factor importance and interaction network.}
We quantify indicator importance by combining squared loadings and explained variance:
\begin{equation}
I_j=\sum_{k=1}^{m} v_{jk}^2\cdot\frac{\lambda_k}{\sum_{\ell=1}^{p}\lambda_\ell}.
\end{equation}
Fig.~\ref{fig:task1_pca_stack}\subref{fig:task1_importance} shows that a limited subset (typically talent, frontier R\&D,
and high-end compute) contributes most to the explained variation.
Finally, the strong-link network induced by $\mathcal{E}$ visualizes system-level coupling:
hub indicators (often infrastructure and investment) connect multiple modules, consistent with a coordinated development mechanism
(Fig.~\ref{fig:task1_pca_stack}\subref{fig:task1_network}).

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[t]{0.40\textwidth}
    \centering
    \includegraphics[width=\linewidth]{\detokenize{figure/task1/fig3_en_Variance Explained Plot for Principal Components.pdf}}
    \caption{Variance explained by PCs.}
    \label{fig:task1_pca}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.40\textwidth}
    \centering
    \includegraphics[width=\linewidth]{\detokenize{figure/task1/fig4_en_Factor Importance Ranking Bar Chart.pdf}}
    \caption{Importance ranking $I_j$.}
    \label{fig:task1_importance}
  \end{subfigure}\\[2pt]
  \begin{subfigure}[t]{0.80\textwidth}
    \centering
    \includegraphics[width=\linewidth]{\detokenize{figure/task1/fig5_en_Strong-Correlation Network or Chord Diagram.pdf}}
    \caption{Strong-correlation interaction network.}
    \label{fig:task1_network}
  \end{subfigure}
  \caption{Low-dimensional structure and key drivers of AI development capability.}
  \label{fig:task1_pca_stack}
\end{figure}

\paragraph{Summary of Task~1.}
Task~1 identifies a dense correlation backbone, coherent indicator modules, and a low-dimensional dominant structure.
These findings motivate (i) objective aggregation in Task~2 and (ii) synergy-aware design in Task~4 using $\mathcal{E}$.

\FloatBarrier