% =========================
% body/7task3.tex
% =========================
\FloatBarrier
\section{Task 3: Forecasting AI Competitiveness (2026--2035)}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.95\textwidth]{figure/task3/lct.png}
  \caption{Overall forecasting and evaluation pipeline of Task~3.}
  \label{fig:task3_framework}
\end{figure}

Fig.~\ref{fig:task3_framework} illustrates the integrated three-phase pipeline adopted in Task~3.
Phase~1 prepares historical indicator sequences and estimates GM(1,1) parameters.
Phase~2 projects country--indicator trajectories for 2026--2035.
Phase~3 evaluates annual AI competitiveness by inheriting the fixed weights and TOPSIS framework from Task~2,
yielding ranking evolution and diagnostic outputs.

Task~3 extends the 2025 evaluation to a dynamic horizon.
The key rule is consistency: \emph{the evaluation mechanism (weights and TOPSIS) is fixed},
and only the indicator trajectories evolve. Therefore, any ranking change during 2026--2035
can be attributed to data-driven indicator dynamics rather than altered standards.

\subsection{Indicator-Level Trend Prediction}

Let $x_{i,j,t}$ be indicator $j$ of country $i$ in year $t$.
For each country--indicator series over 2016--2025, we forecast $\hat{x}_{i,j,t}$ for $t=2026,\dots,2035$ independently.

Given short sequences ($T=10$), GM(1,1) is used as the primary model.
When GM(1,1) backtesting is unsatisfactory, a constrained linear trend model is used as a fallback under the same
non-negativity and truncation rules. One-step-ahead validation (train 2016--2024, predict 2025) uses MAPE as the main metric.
In our pipeline, GM(1,1) covers $44.17\%$ of the $240$ country--indicator series, while the fallback is used for $55.83\%$,
with a median MAPE of $0.1035$.

\begin{figure}[htbp]
\centering
\begin{subfigure}[t]{0.32\textwidth}
  \centering
  \includegraphics[width=\linewidth]{\detokenize{figure/task3/fig2_optimized_en_Score_Gap_Dynamics.pdf}}
  \caption{Score gaps (2026--2035).}
  \label{fig:task3_score_gap}
\end{subfigure}\hfill
\begin{subfigure}[t]{0.32\textwidth}
  \centering
  \includegraphics[width=\linewidth]{\detokenize{figure/task3/fig4_optimized_en_Slope_Chart_2025_2035.pdf}}
  \caption{2025 vs.\ 2035 slope chart.}
  \label{fig:task3_baseline_forecast}
\end{subfigure}\hfill
\begin{subfigure}[t]{0.32\textwidth}
  \centering
  \includegraphics[width=\linewidth]{\detokenize{figure/task3/fig5_optimized_en_Diagnostics_Panel.pdf}}
  \caption{Forecast diagnostics panel.}
  \label{fig:task3_diag_panel}
\end{subfigure}
\caption{Forecasting and evaluation diagnostics for Task~3.}
\label{fig:task3_diag_stack}
\end{figure}

\subsection{Annual Evaluation and Score Evolution}

After forecasting, we construct the predicted indicator matrix for each year $t$:
\[
\hat{X}_t=\bigl(\hat{x}_{i,j,t}\bigr)_{n\times p}.
\]
We keep the entropy weights from Task~2 fixed as $W=(w_1,\dots,w_p)$, and apply the same TOPSIS procedure
to obtain the annual closeness scores $C_{i,t}\in[0,1]$.

Table~\ref{tab:task3_scores_selected} reports the TOPSIS scores for representative years (2026, 2030, 2035),
while Fig.~\ref{fig:task3_score_gap} visualizes the score convergence and the evolution of cross-country gaps.

\begin{table}[htbp]
\centering
\caption{Selected TOPSIS scores $C_{i,t}$ for 2026, 2030, and 2035.}
\label{tab:task3_scores_selected}
\small
\begin{tabular}{lrrr}
\toprule
Country & 2026 & 2030 & 2035 \\
\midrule
United States & 0.653 & 0.644 & 0.633 \\
China & 0.515 & 0.505 & 0.507 \\
India & 0.213 & 0.221 & 0.244 \\
United Arab Emirates & 0.160 & 0.162 & 0.178 \\
France & 0.069 & 0.080 & 0.168 \\
Germany & 0.108 & 0.121 & 0.143 \\
United Kingdom & 0.069 & 0.073 & 0.102 \\
Canada & 0.042 & 0.057 & 0.101 \\
South Korea & 0.055 & 0.066 & 0.097 \\
Japan & 0.054 & 0.060 & 0.093 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Ranking Evolution and Stability}

Countries are ranked annually by $C_{i,t}$.
Fig.~\ref{fig:task3_rank_pair} shows both the ranking trajectories (bump chart) and the stability heatmap.
The top tier remains stable, while rank swaps occur mainly among closely competing mid-/lower-tier countries.

\begin{figure}[htbp]
\centering
\begin{subfigure}[t]{0.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{\detokenize{figure/task3/fig1_optimized_en_Rank_Evolution_Bump_Chart.pdf}}
  \caption{Bump chart (2026--2035).}
  \label{fig:task3_rank_bump}
\end{subfigure}\hfill
\begin{subfigure}[t]{0.49\textwidth}
  \centering
  \includegraphics[width=\linewidth]{\detokenize{figure/task3/fig3_optimized_en_Rank_Stability_Heatmap.pdf}}
  \caption{Rank stability heatmap.}
  \label{fig:task3_rank_heatmap}
\end{subfigure}
\caption{Ranking evolution and stability over the forecast horizon.}
\label{fig:task3_rank_pair}
\end{figure}

\begin{table}[htbp]
\centering
\caption{Rank stability summary (2026--2035).}
\label{tab:task3_rank_stats}
\small
\begin{tabular}{lrrrr}
\toprule
Country & AvgRank & StdRank & BestRank & WorstRank \\
\midrule
United States & 1.00 & 0.00 & 1 & 1 \\
China & 2.00 & 0.00 & 2 & 2 \\
India & 3.00 & 0.00 & 3 & 3 \\
United Arab Emirates & 4.00 & 0.00 & 4 & 4 \\
Germany & 5.20 & 0.40 & 5 & 6 \\
France & 5.90 & 0.54 & 5 & 7 \\
United Kingdom & 7.10 & 0.54 & 6 & 8 \\
South Korea & 8.40 & 0.49 & 8 & 9 \\
Canada & 8.90 & 1.22 & 7 & 10 \\
Japan & 9.50 & 0.50 & 9 & 10 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Interpretation and Robustness}

Because weights and evaluation rules are fixed, ranking changes come solely from predicted indicator trajectories.
Observed swaps are local (small score gaps) rather than structural reversals, consistent with the convergence pattern in Fig.~\ref{fig:task3_score_gap}.
Forecast reliability is supported by the diagnostics in Fig.~\ref{fig:task3_diag_panel}.

\subsection{Summary}

Task~3 couples indicator-level forecasting with the fixed Task~2 evaluation to project 2026--2035 competitiveness.
The results suggest stable global leadership, gradual score convergence, and limited, interpretable mid-tier rank changes,
providing the scenario baseline required by Task~4.

\FloatBarrier